#!/usr/bin/env python3
"""
MinerU PDF Parser - Optimized parallel batch processing

Usage:
    python mineru_parallel.py --dir ./pdfs/ --output ./parsed/ --workers 10
"""

import argparse
import json
import os
import sys
import time
import zipfile
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

import requests

API_BASE = "https://mineru.net/api/v4"

# å…¨å±€ç»Ÿè®¡
stats = {"success": 0, "failed": 0, "total": 0}


def get_token(args):
    return args.token or os.environ.get("MINERU_TOKEN")


def headers(token):
    return {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {token}",
    }


def create_single_task(token, file_path):
    """ä¸ºå•ä¸ªæ–‡ä»¶åˆ›å»ºä¸Šä¼ ä»»åŠ¡"""
    filename = Path(file_path).name
    data_id = Path(file_path).stem
    
    # è·å–ä¸Šä¼ é“¾æ¥
    resp = requests.post(
        f"{API_BASE}/file-urls/batch",
        headers=headers(token),
        json={
            "files": [{"name": filename, "data_id": data_id}],
            "model_version": "vlm",
            "enable_formula": True,
            "enable_table": True,
        },
        timeout=30,
    )
    result = resp.json()
    
    if result.get("code") != 0:
        return None, f"è·å–ä¸Šä¼ é“¾æ¥å¤±è´¥: {result.get('msg')}"
    
    batch_id = result["data"]["batch_id"]
    upload_url = result["data"]["file_urls"][0]
    
    # ä¸Šä¼ æ–‡ä»¶
    with open(file_path, "rb") as f:
        upload_resp = requests.put(upload_url, data=f, timeout=600)
    
    if upload_resp.status_code != 200:
        return None, f"ä¸Šä¼ å¤±è´¥: {upload_resp.status_code}"
    
    return batch_id, data_id


def wait_and_download(token, batch_id, data_id, output_dir, timeout=600, poll=10):
    """ç­‰å¾…è§£æå®Œæˆå¹¶ä¸‹è½½ç»“æœ"""
    start = time.time()
    
    while time.time() - start < timeout:
        try:
            resp = requests.get(
                f"{API_BASE}/extract-results/batch/{batch_id}",
                headers=headers(token),
                timeout=30,
            )
            results = resp.json()["data"]["extract_result"]
            
            if not results:
                time.sleep(poll)
                continue
            
            state = results[0].get("state")
            
            if state == "done":
                # ä¸‹è½½ç»“æœ
                zip_url = results[0].get("full_zip_url")
                return download_result(zip_url, output_dir, data_id)
            
            elif state == "failed":
                return None, results[0].get("err_msg", "è§£æå¤±è´¥")
            
            time.sleep(poll)
            
        except Exception as e:
            time.sleep(poll)
    
    return None, "è¶…æ—¶"


def download_result(url, output_dir, filename):
    """ä¸‹è½½å¹¶è§£å‹ç»“æœ"""
    zip_path = output_dir / f"{filename}.zip"
    
    resp = requests.get(url, stream=True, timeout=300)
    
    with open(zip_path, "wb") as f:
        for chunk in resp.iter_content(8192):
            f.write(chunk)
    
    extract_dir = output_dir / filename
    with zipfile.ZipFile(zip_path) as zf:
        zf.extractall(extract_dir)
    
    zip_path.unlink()
    
    # é‡å‘½å
    md = extract_dir / "full.md"
    if md.exists():
        md.rename(extract_dir / f"{filename}.md")
    
    return extract_dir, None


def process_file(token, file_path, output_dir, index, total):
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    filename = Path(file_path).name
    print(f"  [{index+1}/{total}] å¼€å§‹: {filename}")
    
    try:
        # åˆ›å»ºä»»åŠ¡å¹¶ä¸Šä¼ 
        batch_id, data_id = create_single_task(token, file_path)
        
        if not batch_id:
            print(f"  [{index+1}/{total}] âŒ {filename}: {data_id}")
            return False, filename
        
        # ç­‰å¾…å¹¶ä¸‹è½½
        result, error = wait_and_download(token, batch_id, data_id, output_dir)
        
        if result:
            print(f"  [{index+1}/{total}] âœ… {filename}")
            return True, filename
        else:
            print(f"  [{index+1}/{total}] âŒ {filename}: {error}")
            return False, filename
            
    except Exception as e:
        print(f"  [{index+1}/{total}] âŒ {filename}: {e}")
        return False, filename


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--dir", required=True)
    parser.add_argument("--output", default="./output/")
    parser.add_argument("--token")
    parser.add_argument("--workers", "-w", type=int, default=10, help="å¹¶å‘æ•°")
    parser.add_argument("--resume", action="store_true", help="è·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶")
    
    args = parser.parse_args()
    
    token = get_token(args)
    if not token:
        print("âŒ è¯·è®¾ç½® MINERU_TOKEN")
        sys.exit(1)
    
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # æ”¶é›†æ–‡ä»¶
    input_dir = Path(args.dir)
    pdf_files = sorted(list(input_dir.glob("*.pdf")) + list(input_dir.glob("*.PDF")))
    
    if not pdf_files:
        print("âŒ æœªæ‰¾åˆ° PDF æ–‡ä»¶")
        sys.exit(1)
    
    total = len(pdf_files)
    print(f"\nğŸ“š å¼€å§‹å¹¶è¡Œå¤„ç† {total} ä¸ªæ–‡ä»¶ (å¹¶å‘: {args.workers})\n")
    
    success = 0
    failed = 0
    failed_files = []
    
    start_time = time.time()
    
    # å¹¶è¡Œå¤„ç†
    with ThreadPoolExecutor(max_workers=args.workers) as executor:
        futures = {
            executor.submit(process_file, token, str(f), output_dir, i, total): f
            for i, f in enumerate(pdf_files)
        }
        
        for future in as_completed(futures):
            ok, filename = future.result()
            if ok:
                success += 1
            else:
                failed += 1
                failed_files.append(filename)
    
    # æ±‡æ€»
    elapsed = time.time() - start_time
    print(f"\n{'='*50}")
    print(f"âœ… æˆåŠŸ: {success}")
    print(f"âŒ å¤±è´¥: {failed}")
    print(f"â±ï¸  è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
    
    if failed_files:
        print(f"\nå¤±è´¥æ–‡ä»¶:")
        for f in failed_files:
            print(f"  - {f}")
    
    print(f"\nğŸ“ ç»“æœ: {output_dir}")


if __name__ == "__main__":
    main()
